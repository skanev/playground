> As stated, in dynamic programming, you first solve the subproblems and then
> choose which of them to use in an optimal solution to the problem. Professor
> Capulet claims that she does not always need to solve all the subproblems in
> order to find an optimal solution. She suggests that she can find an optimal
> solution to the matrix-chain multiplication problem by always choosing the
> matrix $A_k$ at which to split the subproduct $A_i A_{i+1} \ldots A_j$ (by
> selecting $k$ to minimize the quantity $p_{i-1} p_k p_j$) _before_ solving the
> subproblems. Find an instance of the matrix-chain multiplication problem for
> which this greedy approach yields a suboptimal solution.

An example would be a matrix chain $10 \times 4 \times 3 \times 2$, where:

$$
\begin{aligned}
  A_1 & \in \mathbb{R}^{10} \times \mathbb{R}^4 \\\\
  A_2 & \in \mathbb{R}^4 \times \mathbb{R}^3 \\\\
  A_3 & \in \mathbb{R}^3 \times \mathbb{R}^2 \\\\
\end{aligned}
$$

The first choice would be whether to first multiply $A_1 A_2$ or $A_2 A_3$.
Looking just at $p_{i-1} p_k p_j$, the options will be 

$$
\begin{aligned}
  C_1 &= p_1 p_2 p_4 = 10 \cdot 4 \cdot 2 &= 80 \\\\
  C_2 &= p_1 p_3 p_4 = 10 \cdot 3 \cdot 2 &= 60 \\\\
\end{aligned}
$$

With this information, ~~Juliet~~ Professor Capulet would opt in for the second
option. Yet, this would be premature!

In the second case, she will have to continue with then multiplying $A_1 A_2$
with $10 \cdot 4 \cdot 3 = 120$ additional scalar operations, bringing the tally
to $180$.

If she instead, chilled a bit and waited to see how things would play out, she
would discover that in the other option there would be only $4 \cdot 3 \cdot 2 =
24$ more scalar operations to perform, in a total of $104$.
